# Study and Visualization of Interpretable Machine Learning 

The main task is to implement few Interpretable Machine Learning models that could help answer questions of the underlying classification black-box model. The main aim here is keeping the end-user in mind to answer his/her several questions such as:
  1. Why did the model predict it this way?
  2. Is there a specific variable that is responsible for a particular prediction of an instance's classification?
  
## Dataset

The dataset considered for this particular task are the demographics and morphological features of 100 intracranial aneurysms recorded at the university hospital of Magdeburg, Germany. This small dataset corresponds to 93 patients. There are few missing values in the otherwise clean data. Due to the issues of data privacy, the dataset is not uploaded in the repository along with the source code and other resources. 

## Model Design

Even though the intent of the task is not to come up with the best model for the task, two were chosen as a motivation from http://wwwisg.cs.uni-magdeburg.de/visualisierung/wiki/data/media/files/misc/niemann_2018_cbms.pdf which was performed on the same dataset - Gradient Boosting Trees and Support Vector Machines. 
